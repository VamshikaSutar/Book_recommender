{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from recsys_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y (4778, 443) R (4778, 443)\n",
      "X (4778, 10)\n",
      "W (443, 10)\n",
      "b (1, 443)\n",
      "num_features 10\n",
      "num_books 4778\n",
      "num_users 443\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X, W, b, num_books, num_features, num_users = load_precalc_params_small()\n",
    "Y, R = load_ratings_small()\n",
    "\n",
    "print(\"Y\", Y.shape, \"R\", R.shape)\n",
    "print(\"X\", X.shape)\n",
    "print(\"W\", W.shape)\n",
    "print(\"b\", b.shape)\n",
    "print(\"num_features\", num_features)\n",
    "print(\"num_books\",   num_books)\n",
    "print(\"num_users\",    num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "bxm1O_wbodYF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating for book 1 : 3.400 / 5\n"
     ]
    }
   ],
   "source": [
    "#  From the matrix, we can compute statistics like average rating.\n",
    "tsmean =  np.mean(Y[0, R[0, :].astype(bool)])\n",
    "print(f\"Average rating for book 1 : {tsmean:0.3f} / 5\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 13.67\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_users_r = 4\n",
    "num_books_r = 5 \n",
    "num_features_r = 3\n",
    "\n",
    "X_r = X[:num_books_r, :num_features_r]\n",
    "W_r = W[:num_users_r,  :num_features_r]\n",
    "b_r = b[0, :num_users_r].reshape(1,-1)\n",
    "Y_r = Y[:num_books_r, :num_users_r]\n",
    "R_r = R[:num_books_r, :num_users_r]\n",
    "\n",
    "\n",
    "J = cofi_cost_func(X_r, W_r, b_r, Y_r, R_r, 0);\n",
    "print(f\"Cost: {J:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost with regularization: 28.09\n"
     ]
    }
   ],
   "source": [
    "\n",
    "J = cofi_cost_func(X_r, W_r, b_r, Y_r, R_r, 1.5);\n",
    "print(f\"Cost with regularization: {J:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def cofi_cost_func_v(X, W, b, Y, R, lambda_):\n",
    "    \n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 13.67\n",
      "Cost (with regularization): 28.09\n"
     ]
    }
   ],
   "source": [
    "\n",
    "J = cofi_cost_func_v(X_r, W_r, b_r, Y_r, R_r, 0);\n",
    "print(f\"Cost: {J:0.2f}\")\n",
    "\n",
    "\n",
    "J = cofi_cost_func_v(X_r, W_r, b_r, Y_r, R_r, 1.5);\n",
    "print(f\"Cost (with regularization): {J:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "id": "WJO8Jr0UodYR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New user ratings:\n",
      "\n",
      "Rated 5.0 for  Shrek (2001)\n",
      "Rated 5.0 for  Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Rated 2.0 for  Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
      "Rated 5.0 for  Harry Potter and the Chamber of Secrets (2002)\n",
      "Rated 5.0 for  Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "Rated 5.0 for  Lord of the Rings: The Return of the King, The (2003)\n",
      "Rated 3.0 for  Eternal Sunshine of the Spotless Mind (2004)\n",
      "Rated 5.0 for  Incredibles, The (2004)\n",
      "Rated 2.0 for  Persuasion (2007)\n",
      "Rated 5.0 for  Toy Story 3 (2010)\n",
      "Rated 3.0 for  Inception (2010)\n",
      "Rated 1.0 for  Louis Theroux: Law & Disorder (2008)\n",
      "Rated 1.0 for  Nothing to Declare (Rien à déclarer) (2010)\n"
     ]
    }
   ],
   "source": [
    "bookList, bookList_df = load_Movie_List_pd()\n",
    "\n",
    "my_ratings = np.zeros(num_movies)          \n",
    "my_ratings[2700] = 5 \n",
    "\n",
    "\n",
    "my_ratings[2609] = 2;\n",
    "\n",
    "\n",
    "my_ratings[929]  = 5   \n",
    "my_ratings[246]  = 5   \n",
    "my_ratings[2716] = 3   \n",
    "my_ratings[1150] = 5   \n",
    "my_ratings[382]  = 2   \n",
    "my_ratings[366]  = 5   \n",
    "my_ratings[622]  = 5   \n",
    "my_ratings[988]  = 3   \n",
    "my_ratings[2925] = 1   \n",
    "my_ratings[2937] = 1   \n",
    "my_ratings[793]  = 5   \n",
    "my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n",
    "\n",
    "print('\\nNew user ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0 :\n",
    "        print(f'Rated {my_ratings[i]} for  {bookList_df.loc[i,\"title\"]}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add these reviews to $Y$ and $R$ and normalize the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "\n",
    "Y, R = load_ratings_small()\n",
    "\n",
    "\n",
    "Y = np.c_[my_ratings, Y]\n",
    "\n",
    "\n",
    "R = np.c_[(my_ratings != 0).astype(int), R]\n",
    "\n",
    "\n",
    "Ynorm, Ymean = normalizeRatings(Y, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "num_books, num_users = Y.shape\n",
    "num_features = 100\n",
    "\n",
    "\n",
    "tf.random.set_seed(123456) \n",
    "W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\n",
    "X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\n",
    "b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 2566.61\n",
      "Training loss at iteration 10: 2446.39\n",
      "Training loss at iteration 20: 2348.73\n",
      "Training loss at iteration 30: 2268.78\n",
      "Training loss at iteration 40: 2202.87\n",
      "Training loss at iteration 50: 2148.14\n",
      "Training loss at iteration 60: 2102.37\n",
      "Training loss at iteration 70: 2063.85\n",
      "Training loss at iteration 80: 2031.19\n",
      "Training loss at iteration 90: 2003.34\n",
      "Training loss at iteration 100: 1979.44\n",
      "Training loss at iteration 110: 1958.79\n",
      "Training loss at iteration 120: 1940.86\n",
      "Training loss at iteration 130: 1925.19\n",
      "Training loss at iteration 140: 1911.43\n",
      "Training loss at iteration 150: 1899.29\n",
      "Training loss at iteration 160: 1888.52\n",
      "Training loss at iteration 170: 1878.92\n",
      "Training loss at iteration 180: 1870.33\n",
      "Training loss at iteration 190: 1862.61\n"
     ]
    }
   ],
   "source": [
    "iterations = 200\n",
    "lambda_ = 1\n",
    "for iter in range(iterations):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        \n",
    "        cost_value = cofi_cost_func_v(X, W, b, Ynorm, R, lambda_)\n",
    "\n",
    "    \n",
    "    grads = tape.gradient( cost_value, [X,W,b] )\n",
    "\n",
    "    \n",
    "    optimizer.apply_gradients( zip(grads, [X,W,b]) )\n",
    "\n",
    "    \n",
    "    if iter % 10 == 0:\n",
    "        print(f\"Training loss at iteration {iter}: {cost_value:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ns266wKtodYT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting rating 4.74 for movie Colourful (Karafuru) (2010)\n",
      "Predicting rating 4.58 for movie One I Love, The (2014)\n",
      "Predicting rating 4.58 for movie Laggies (2014)\n",
      "Predicting rating 4.58 for movie Delirium (2014)\n",
      "Predicting rating 4.55 for movie Into the Forest of Fireflies' Light (2011)\n",
      "Predicting rating 4.54 for movie Particle Fever (2013)\n",
      "Predicting rating 4.54 for movie Martin Lawrence Live: Runteldat (2002)\n",
      "Predicting rating 4.54 for movie Battle Royale 2: Requiem (Batoru rowaiaru II: Chinkonka) (2003)\n",
      "Predicting rating 4.54 for movie Into the Abyss (2011)\n",
      "Predicting rating 4.54 for movie Eichmann (2007)\n",
      "\n",
      "\n",
      "Original vs Predicted ratings:\n",
      "\n",
      "Original 5.0, Predicted 4.89 for Shrek (2001)\n",
      "Original 5.0, Predicted 4.86 for Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Original 2.0, Predicted 2.18 for Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
      "Original 5.0, Predicted 4.85 for Harry Potter and the Chamber of Secrets (2002)\n",
      "Original 5.0, Predicted 4.85 for Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "Original 5.0, Predicted 4.87 for Lord of the Rings: The Return of the King, The (2003)\n",
      "Original 3.0, Predicted 3.03 for Eternal Sunshine of the Spotless Mind (2004)\n",
      "Original 5.0, Predicted 4.89 for Incredibles, The (2004)\n",
      "Original 2.0, Predicted 2.14 for Persuasion (2007)\n",
      "Original 5.0, Predicted 4.77 for Toy Story 3 (2010)\n",
      "Original 3.0, Predicted 3.01 for Inception (2010)\n",
      "Original 1.0, Predicted 1.39 for Louis Theroux: Law & Disorder (2008)\n",
      "Original 1.0, Predicted 1.26 for Nothing to Declare (Rien à déclarer) (2010)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
    "\n",
    "\n",
    "pm = p + Ymean\n",
    "\n",
    "my_predictions = pm[:,0]\n",
    "\n",
    "\n",
    "ix = tf.argsort(my_predictions, direction='DESCENDING')\n",
    "\n",
    "for i in range(17):\n",
    "    j = ix[i]\n",
    "    if j not in my_rated:\n",
    "        print(f'Predicting rating {my_predictions[j]:0.2f} for book {bookList[j]}')\n",
    "\n",
    "print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {bookList[i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
